{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb774c1-b544-4b8b-8e9b-46569a09138e",
   "metadata": {},
   "source": [
    "## Welcome to CIVE 202\n",
    "\n",
    "This is our first Lab and this is our first Jupyter Notebook.  Today we'll be exploring how Jupyter Notebooks work, how to load in data to Jupyter Notebooks, and how to look at the data to verify the data has loaded correctly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569a768b-bbee-4e0d-9d36-9690a9786d72",
   "metadata": {},
   "source": [
    "### Step 1: Set up your notebook\n",
    "\n",
    "Every notebook should start with loading in the relevant packages that have useful functions you plan to use in your code.  This helps organize your code and ensure that you have all the functions you need before you dive into data analysis.  Let's load in some of the key packages necessary for CIVE 202 in the Code Cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ae8737-b7be-423e-a60d-e988ad901df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Show you have imported the pandas package in the space below\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3cf8a6-fa64-4ce9-add6-b79cbddf57e0",
   "metadata": {},
   "source": [
    "Next, set your working directory. This is the location where all of your data files and Python coding files \"live\" for any project so that the computer understands what files to reference. In Jupyter Notebooks your working directory is the folder where your working notebook (this notebook) lives.  Any data files that you want to upload to your notebook must be in your working directory in order for them to interface with Jupyter Notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd69c59-1347-440c-8503-e749ffffac0d",
   "metadata": {},
   "source": [
    "### Step 2: Load in all relevant datasets and verify proper loading\n",
    "\n",
    "Next, read in the data file you want to use in your data analysis. Use the `pd.read_csv()` function from the pandas library to read in your CSV. IMPORTANT: Reading in CSVs is better than Excel. Why? CSVs do not have complicated formatting that Python will try to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "908de2de-a5d4-40c1-9e35-8d35d00f61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Show you have imported the Air Quality data as a CSV and assigned it to a variable\n",
    "air_data = pd.read_csv(\"AirQuality_Daily_StudentVersion.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31efcb06-4c7d-4a2e-a371-4691ae64474d",
   "metadata": {},
   "source": [
    "We may also want to make sure that the new data set we imported is a dataframe.  Dataframes are a type of data structure in Python where each column is interpreted as a different variable that can then be manipulated.  If we want to coerce a data set into a data frame, we can use the following syntax.  Note that this syntax overwrites the `air_data` we created above!  Also, the `pd.` before the function tells Python that this function comes from the pandas package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13270677-a75e-4a21-95a5-e85d7fd18af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show you have changed your variable above into a dataframe\n",
    "air_data_df = pd.DataFrame(air_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e544bf-582b-4317-ab62-fbd585ac50d9",
   "metadata": {},
   "source": [
    "Next, we can use the print function to examine what types of data are present in our CSV. This gives us a chance to examine what types of data are present and what variables we will be able to manipulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70015422-9b5f-4d86-9656-fe4bf7a06a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print your dataframe in this space\n",
    "print(air_data_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e62822-8908-4317-9df4-06a9d97ffbd1",
   "metadata": {},
   "source": [
    "There are three other ways we can check our dataframe:\n",
    "1. Print out the column names by using `.column`s with the dataframe.\n",
    "2. Print out the first 5-10 rows using `.head()`\n",
    "3. Print out the last 5-10 rows using `.tail()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1456c7b8-3a4a-4953-be13-0f979e15aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the names of the columns in the dataframe\n",
    "print(air_data_df.column())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370bc3e7-2d46-4635-b475-f1dfc8cffd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the first 5 rows of a dataframe\n",
    "print(air_data_df.head(5))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d6bcbbf-0a05-4a55-bfca-b7685f5ec6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the last 20 rows of a dataframe\n",
    "print(air_data_df.tail(20))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
